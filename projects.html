<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- 
    - primary meta tags
  -->
  <title>ynr</title>
  <meta name="title" content="Nikhil Reddy-Developer.">
  <meta name="description" content="This is my  personal portfolio">

  <!-- 
    - favicon
  -->
  <link rel="shortcut icon" href="./favicon.png" type="image/svg+xml">

  <!-- 
    - google font link
  -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Manrope:wght@500;700&display=swap" rel="stylesheet">

  <!-- 
    - custom css link
  -->
  <link rel="stylesheet" href="./assets/css/style.css">

  <!-- 
    - preload images
  -->
  <link rel="preload" as="image" href="./assets/images/hero-banner.jpg">
  <link rel="preload" as="image" href="./assets/images/Blog.svg">

</head>

<body>

  <!-- 
    - #HEADER
  -->

  <header class="header" data-header>
    <div class="container">

      <a href="#" class="logo">
<h1>NIKHIL REDDY YERRAGONDU</h1>      </a>

      <nav class="navbar" data-navbar>

        <div class="navbar-top">
          <a href="#" class="logo">
            <img src="./assets/images/logo-light.svg" width="64" height="24" alt="ynr home">
          </a>

          <button class="nav-close-btn" aria-label="close menu" data-nav-toggler>
            <ion-icon name="close-outline" aria-hidden="true"></ion-icon>
          </button>
        </div>

        <ul class="navbar-list">

          <li>
            <a href="index.html" class="navbar-link">Home</a>
          </li>

          <li>
            <a href="about.html" class="navbar-link">About</a>
          </li>
          <li>
            <a href="certificates.html" class="navbar-link">Certificates</a>
          </li>

          <!-- <li>
            <a href="#" class="navbar-link">Projects</a>
          </li> -->

          <!-- <li>
            <a href="#" class="navbar-link">Blog</a>
          </li> -->

          <!-- <li>
            <a href="#" class="navbar-link">Contact</a>
          </li> -->

        </ul>

        <div class="wrapper">
            <a href="yerragondunikhilreddy@gmail.com" class="contact-link">yerragondunikhilreddy@gmail.com</a>

          <!-- <a href="tel:001234567890" class="contact-link">00 (123) 456 78 90</a> -->
        </div>

        <ul class="social-list">

          <li>
            <a href="https://x.com/ynr0007" class="social-link">
              <ion-icon name="logo-twitter"></ion-icon>
            </a>
          </li>

          <li>
            <a href="https://github.com/ynr0007" class="social-link">
              <ion-icon name="logo-github"></ion-icon>
            </a>
          </li>

          <!-- <li>
            <a href="#" class="social-link">
              <ion-icon name="logo-dribbble"></ion-icon>
            </a>
          </li> -->

          <li>
            <a href="https://www.linkedin.com/in/ynr0007/" class="social-link">
              <ion-icon name="logo-linkedin"></ion-icon>
            </a>
          </li>

          <!-- <li>
            <a href="#" class="social-link">
              <ion-icon name="logo-youtube"></ion-icon>
            </a>
          </li>-->

        </ul>
      </nav>

      <button class="nav-open-btn" aria-label="open menu" data-nav-toggler>
        <ion-icon name="menu-outline" aria-hidden="true"></ion-icon>
      </button>

      <div class="overlay" data-nav-toggler data-overlay></div>

    </div>
  </header>





  <main>
    <article>

      <!-- 
        - #HERO
      -->

    
    





    

       


      <!-- 
        - #PROJECT
      -->

      <section class="section project" aria-labelledby="project-label">
        <div class="container">

          <br><br>

          <ul>

            <li>
              <div class="project-card project-card-1" style="background-color: #f8f5fb">
            
                <div class="card-content" data-reveal="left">
            
                  <p class="card-tag" style="color: #a07cc5"> Project 1</p>
            
                  <h3 class="h3 card-title"> Blockchain-Based E-Voting System using Facial Recognition </h3>
                
                  <p class="card-text">
                    Imagine a world where the democratic process is not only accessible but secure and tamper-proof. Our groundbreaking web application transforms the way we vote, combining cutting-edge blockchain technology with advanced facial recognition to create an election system that's both transparent and invulnerable to fraud.
                  </p>
            
                  <p class="card-text">
                    <strong>Technologies Used:</strong>
                    <ul>
                      <li><strong>MongoDB:</strong> Our robust database management system stores candidate profiles, election details, and user information securely and efficiently.</li>
                      <li><strong>Truffle and Ganache:</strong> These tools power our blockchain integration, enabling seamless smart contract deployment and ensuring that every vote is recorded in an immutable ledger.</li>
                      <li><strong>MetaMask:</strong> This essential tool manages Ethereum transactions, allowing users to interact with the blockchain effortlessly.</li>
                      <li><strong>Python:</strong> Harnessing the power of Python, we’ve implemented facial recognition using libraries like OpenCV and face_recognition, ensuring that each voter is authenticated with unparalleled accuracy.</li>
                    </ul>
                  </p>
                  
                  <p class="card-text">
                    <strong>Blockchain Integration:</strong> Smart contracts are at the heart of our system, compiled and deployed with precision using Truffle. Transactions are handled through MetaMask and Ganache, creating a foolproof record of every vote and ensuring the integrity of the election process.
                  </p>
                  
                  <p class="card-text">
                    <strong>Facial Recognition:</strong> Security meets innovation with our advanced facial recognition technology. By leveraging Python libraries, we authenticate users through their unique facial features, adding an extra layer of protection and trust to the voting experience.
                  </p>
                  
                  <p class="card-text">
                    <strong>Third-Party Email Verification:</strong> We’ve integrated robust email verification processes to safeguard user registration and communication, ensuring a seamless and secure experience for every participant.
                  </p>
                  
                  <p class="card-text">
                    This project not only sets a new standard for election security but also redefines the trust and transparency in voting systems. With our blockchain-based e-voting system, we are pioneering a future where every vote counts and every election is conducted with integrity.
                  </p>
            
                  <a href="https://github.com/ynr0007/Blockchain-Based-E-Voting-System-using-Facial-Recognition.git" class="btn-text" style="color: #3f78e0">
                    <span class="span">View Project 1</span>
                    <ion-icon name="arrow-forward-outline" aria-hidden="true"></ion-icon>
                  </a>
            
                  <a href="#" class="btn-text" style="color: #a07cc5">
                    <!-- <span class="span">See Project</span> -->
                    <!-- <ion-icon name="arrow-forward-outline" aria-hidden="true"></ion-icon> -->
                  </a>
            
                </div>
            
                <figure class="card-banner" data-reveal="right">
                  <img src="./assets/images/vote1.webp" width="300" height="100" loading="lazy" alt="Web Design" style="float: right;" >
                </figure>
                <br>
              </div>
            </li>
            

            <br> 
            
            <li>
              <div class="project-card project-card-2" style="background-color: #f1f5fd">
            
                <div class="card-content" data-reveal="right">
            
                  <p class="card-tag" style="color: #3f78e0">Project 2</p>
            
                  <h3 class="h3 card-title">Video Forgery Detection Using Hybrid Architecture</h3>
            
                  <p class="card-text">
                    In the battle against video forgery, our innovative approach leverages the power of hybrid deep learning architectures to ensure authenticity and integrity. By seamlessly integrating Convolutional Neural Networks (CNNs) with Recurrent Neural Networks (RNNs), we deliver a robust solution that captures both spatial and temporal nuances in video content.
                  </p>
            
                  <p class="card-text">
                    <strong>Key Features of the System:</strong>
                  </p>
                  
                  <p class="card-text">
                    <strong>Hybrid CNN-RNN Architecture:</strong> Our cutting-edge system combines the strengths of CNNs and RNNs, enabling it to extract rich spatial features and capture intricate temporal patterns within videos. This hybrid approach ensures comprehensive analysis of video content for accurate forgery detection.
                  </p>
            
                  <p class="card-text">
                    <strong>Feature Extraction:</strong>
                  </p>
            
                  <p class="card-text">
                    <strong>Xception Network:</strong> Utilizing the 71-layer Xception architecture, we extract detailed spatial features from video frames. This network processes inputs at a resolution of 299 x 299 pixels, providing a deep understanding of frame-level details.
                  </p>
            
                  <p class="card-text">
                    <strong>Inception-v3 Network:</strong> Complementing the Xception model, the 48-layer Inception-v3 network enhances feature extraction by analyzing additional frame-level attributes, enriching our detection capabilities.
                  </p>
            
                  <p class="card-text">
                    <strong>Temporal Modeling:</strong> Our system incorporates Gated Recurrent Units (GRUs) to model the sequential dependencies and dynamic changes over time within video sequences. This enables the detection of temporal anomalies that may indicate tampering or forgery.
                  </p>
            
                  <p class="card-text">
                    <strong>Frame Handling:</strong> To handle videos with varying numbers of frames, our system converts video sequences into 3D tensor representations. We standardize frame counts by padding with zeros when necessary, ensuring uniformity and consistency in the analysis process.
                  </p>
            
                  <p class="card-text">
                    <strong>Processing Steps:</strong>
                  </p>
            
                  <p class="card-text">
                    Capture Video Frames: We extract frames from the video for analysis.
                  </p>
            
                  <p class="card-text">
                    Extract Frames: Frames are processed until the maximum frame count is reached.
                  </p>
            
                  <p class="card-text">
                    Padding: Zero frames are added if the number of frames falls short of the predefined maximum, standardizing input for reliable analysis.
                  </p>
            
                  <p class="card-text">
                    This approach not only advances the state-of-the-art in video forgery detection but also sets a new benchmark for security and authenticity in digital media. Our system’s ability to blend spatial and temporal insights makes it a powerful tool for ensuring the integrity of video content in an increasingly digital world.
                  </p>
            
                  <br>
                  <a href="https://github.com/ynr0007/VIDEO-FORGERY-DETECTION-USING-HYBRID-ARCHITECTURE.git" class="btn-text" style="color: #3f78e0">
                    <span class="span">View Project 2</span>
                    <ion-icon name="arrow-forward-outline" aria-hidden="true"></ion-icon>
                  </a>
                  </br>
            
                </div>
            
                <figure class="card-banner" data-reveal="left">
                  <img src="./assets/images/p2.webp" width="350" height="200" loading="lazy" alt="Web Design">
                </figure>
            
              </div>
            </li>
            
            <br> 
            <li>
              <div class="project-card project-card-1" style="background-color: #f8f5fb">
            
                <div class="card-content" data-reveal="left">
            
                  <p class="card-tag" style="color: #a07cc5">Project 3</p>
            
                  <h3 class="h3 card-title">Facial Video Forgery Detection Model</h3>
            
                  <p class="card-text">
                    In an era where digital manipulation is becoming increasingly sophisticated, our Facial Video Forgery Detection Model stands at the forefront of combating face tampering. Designed to detect tampering techniques such as Deepfake and Face2Face, this model leverages advanced deep learning approaches to deliver high accuracy and reliability.
                  </p>
            
                  <p class="card-text">
                    <strong>Key Features of the Model:</strong>
                  </p>
            
                  <p class="card-text">
                    <strong>Advanced Tampering Detection:</strong> Our model effectively identifies face tampering techniques, including Deepfake and Face2Face, using state-of-the-art deep learning methods. By focusing on mesoscopic image properties, it can discern subtle anomalies that may indicate manipulation.
                  </p>
            
                  <p class="card-text">
                    <strong>Deep Learning Architecture:</strong>
                  </p>
            
                  <p class="card-text">
                    <strong>Efficient Feature Extraction:</strong> We adopt an intermediate deep neural network approach with a streamlined architecture. This design ensures efficient feature extraction and classification while maintaining high performance.
                  </p>
            
                  <p class="card-text">
                    <strong>Low-Parameter Networks:</strong> Our model uses networks with fewer parameters, drawing from proven image classification models. This not only enhances computational efficiency but also ensures robust detection capabilities.
                  </p>
            
                  <p class="card-text">
                    <strong>Performance Metrics:</strong>
                  </p>
            
                  <p class="card-text">
                    <strong>Deepfake Detection:</strong> Achieves an impressive detection rate of over 98%, demonstrating exceptional accuracy in identifying Deepfake manipulations.
                  </p>
            
                  <p class="card-text">
                    <strong>Face2Face Detection:</strong> Reaches a robust detection rate of 95%, effectively addressing another prevalent face tampering technique.
                  </p>
            
                  <p class="card-text">
                    <strong>Dataset Evaluation:</strong> Our model is rigorously evaluated on both existing and custom datasets, ensuring that it performs well across diverse scenarios and various forms of video content. This comprehensive evaluation underpins the model's reliability and robustness.
                  </p>
            
                  <p class="card-text">
                    By combining deep learning techniques with an efficient network architecture, our model offers a powerful solution for detecting face tampering in videos. Its high accuracy and efficiency make it a valuable tool in the ongoing effort to maintain the integrity of digital media.
                  </p>
            
                  <a href="https://github.com/ynr0007/Facial-Video-Forgery-Detection.git" class="btn-text" style="color: #a07cc5">
                    <span class="span">View Project 3</span>
                    <ion-icon name="arrow-forward-outline" aria-hidden="true"></ion-icon>
                  </a>
            
                </div>
            
                <figure class="card-banner" data-reveal="right">
                  <img src="./assets/images/p3.webp" width="300" height="100" loading="lazy" alt="Web Design" style="float: right;">
                </figure>
                <br>
              </div>
            </li>
            
            <br> 
            <li>
              <div class="project-card project-card-1" style="background-color: #f8f5fb; display: flex; align-items: center;">
            
                <figure class="card-banner" style="margin-right: 20px;">
                  <img src="./assets/images/ibse.jpg" width="300" height="100" loading="lazy" alt="Web Design">
                </figure>
              
                <div class="card-content" data-reveal="left">
                  <p class="card-tag" style="color: #a07cc5">Project 4</p>
                  <h3 class="h3 card-title">Image-Based Search Engine</h3>
                  <p class="card-text">
                    Transforming the way we search for images, our innovative image-based search engine combines the power of deep learning with user-friendly web technologies. Built with Keras and Flask, this solution offers an intuitive and effective way to find similar images, even when faced with modifications or user-specific preferences.
                  </p>
                  <p class="card-text">
                    <strong>1. Feature Extraction:</strong> Utilizes the VGG16 model, a robust pre-trained network, to extract deep features from images. This allows us to capture rich, high-level representations of image content, crucial for accurate similarity matching.
                  </p>
                  <p class="card-text">
                    <strong>2. Web Server Implementation:</strong> Operates through a Flask-based web server, providing a seamless interface for querying images. Users can upload or specify images, and the server handles requests to find and display similar images.
                  </p>
                  <p class="card-text">
                    <strong>3. Search Capabilities:</strong> Demonstrates the ability to retrieve similar images even with modifications. It addresses challenges like image alterations and user-specific search history, ensuring relevant results for diverse queries.
                  </p>
                  <a href="https://github.com/ynr0007/IMAGE-BASED-SEARCH-ENGINE.git" class="btn-text" style="color: #a07cc5">
                    <span class="span">View Project 4</span>
                    <ion-icon name="arrow-forward-outline" aria-hidden="true"></ion-icon>
                  </a>
                </div>
            
              </div>
            </li>
            
            <br> 
            <li>
              <div class="project-card project-card-1" style="background-color: #f8f5fb">
            
                <div class="card-content" data-reveal="left">
            
                  <p class="card-tag" style="color: #a07cc5"> Project 5</p>
            
                  <h3 class="h3 card-title">Human Activity Recognition System</h3>
            
                  <p class="card-text">
                    Our Human Activity Recognition (HAR) system integrates advanced computer vision and deep learning techniques to identify and annotate actions in video footage. Utilizing Detectron2 for keypoint detection and a custom LSTM model for action recognition, this system delivers precise and actionable insights from video data.
                  </p>
            
                  <p class="card-text">
                    <strong>1. Video Input Processing:</strong> The system accepts video inputs, processes each frame, and employs the Detectron2 model for accurate keypoint detection. This enables detailed analysis of human poses and movements throughout the video.
                  </p>
            
                  <p class="card-text">
                    <strong>2. Buffer Management:</strong> Keypoint data from each frame are stored in a buffer of size 32, which operates in a sliding window fashion. This approach ensures that temporal information is preserved and effectively utilized for action recognition.
                  </p>
            
                  <p class="card-text">
                    <strong>3. Action Identification:</strong> The contents of the buffer are fed into a trained Long Short-Term Memory (LSTM) model, which identifies and classifies human actions based on the temporal patterns in the keypoint data.
                  </p>
            
                  <p class="card-text">
                    <strong>4. Web Application Interface:</strong> A user-friendly web application built with Flask allows users to upload and process video inputs. The interface is designed to facilitate easy interaction with the system and display results effectively.
                  </p>
            
                  <p class="card-text">
                    <strong>5. Action Annotation:</strong> Detected actions are annotated directly on the video, providing clear visual feedback of the recognized activities. This annotated video is then displayed to the user, offering an intuitive view of the action recognition results.
                  </p>
            
                  <a href="https://github.com/ynr0007/Human-Activity-recognition.git" class="btn-text" style="color: #a07cc5">
                    <span class="span">View Project 5</span>
                    <ion-icon name="arrow-forward-outline" aria-hidden="true"></ion-icon>
                  </a>
            
                </div>
            
                <figure class="card-banner" data-reveal="right">
                  <img src="./assets/images/har.jpeg" width="300" height="100" loading="lazy" alt="Web Design" style="float: right;">
                </figure>
                <br>
              </div>
            </li>
            
           

           
          </ul>

        </div>
      </section>





      <!-- 
        - #CONTACT
      -->

      <section class="section contact" aria-label="contact">
        <div class="container">

          <div class="contact-card">

            <div class="contact-content" data-reveal="left">

              <div class="card-icon">
                <img src="./assets/images/icon-5.svg" width="44" height="44" loading="lazy" alt="envelop icon">
              </div>

              <h2 class="h2 section-title">If you like what you see, let's work together.</h2>

              <p class="section-text">
                I bring rapid solutions to make the life of people easier. Have any questions? Reach out to me 
            by Email and I will get back to you shortly.
              </p>
              <p class=" card-tag" style="color: #d16b86">Email: yerragondunikhilreddy@gmail.com</p>

              <p class=" card-tag" style="color: #d16b86">GitHub: https://github.com/ynr0007</p>
              <!-- In the navbar under "Certificates" or "Contact" -->
<li class="resume-link">
    <a href="./assets/resume/resume.pdf" class="navbar-link" download>Download Resume</a>
</li>



            </div>

            <!-- <form action="" class="contact-form" data-reveal="right">

              <div class="input-wrapper">
                <input type="text" name="name" placeholder="Name *" required class="input-field">

                <input type="email" name="email_address" placeholder="Email *" required class="input-field">
              </div>

              <textarea name="message" placeholder="Message *" required class="input-field"></textarea>

              <button type="submit" class="btn btn-secondary">Send message</button>

            </form> -->

          </div>

        </div>
      </section>

    </article>
  </main>





  <!-- 
    - #FOOTER
  -->

  <footer class="footer">
    <div class="container">

      <p class="copyright">
        © 2024 Nikhil Reddy. All rights reserved.
      </p>

      <!-- <ul class="social-list">

        <li>
          <a href="#" class="social-link">
            <ion-icon name="logo-twitter"></ion-icon>
          </a>
        </li>

        <li>
          <a href="#" class="social-link">
            <ion-icon name="logo-facebook"></ion-icon>
          </a>
        </li>

        <li>
          <a href="#" class="social-link">
            <ion-icon name="logo-dribbble"></ion-icon>
          </a>
        </li>

        <li>
          <a href="#" class="social-link">
            <ion-icon name="logo-instagram"></ion-icon>
          </a>
        </li>

        <li>
          <a href="#" class="social-link">
            <ion-icon name="logo-youtube"></ion-icon>
          </a>
        </li>

      </ul> -->

    </div>
  </footer>





  <!-- 
    - custom js link
  -->
  <script src="./assets/js/script.js"></script>

  <!-- 
    - ionicon link
  -->
  <script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
  <script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script>

</body>

</html>